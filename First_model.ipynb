{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":126119,"databundleVersionId":14953781}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q numpy pandas opencv-python-headless rasterio torch torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:31:20.693762Z","iopub.execute_input":"2026-02-20T04:31:20.694161Z","iopub.status.idle":"2026-02-20T04:31:27.308082Z","shell.execute_reply.started":"2026-02-20T04:31:20.694114Z","shell.execute_reply":"2026-02-20T04:31:27.306355Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# =============================================================================\n# ICPR 2026 – Beyond Visible Spectrum: AI for Agriculture\n# COMPLETE TRAINING + INFERENCE PIPELINE\n#\n# CONFIRMED DATASET STRUCTURE:\n#   /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/\n#     Kaggle_Prepared/\n#       train/\n#         RGB/   Health_hyper_1.png   rust_hyper_2.png   other_hyper_12.png ...\n#         MS/    Health_hyper_1.tif   rust_hyper_2.tif   other_hyper_12.tif ...\n#         HS/    Health_hyper_1.tif   rust_hyper_2.tif   other_hyper_12.tif ...\n#       val/\n#         RGB/   val_02afcb0e.png  ...  (no class in filename)\n#         MS/    val_02afcb0e.tif  ...\n#         HS/    val_02afcb0e.tif  ...\n#\n# CLASS EXTRACTION: parsed from filename prefix (case-insensitive)\n#   \"Health_hyper_1.png\"  → Health (label=0)\n#   \"rust_hyper_2.png\"    → Rust   (label=1)\n#   \"other_hyper_12.png\"  → Other  (label=2)\n#\n# PASTE THIS ENTIRE FILE INTO ONE SINGLE KAGGLE CELL AND RUN.\n# Do NOT split across cells — old cached cell state causes assertion errors.\n# =============================================================================\n\nimport os, sys, random, warnings\nfrom pathlib import Path\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport rasterio\nfrom rasterio.errors import NotGeoreferencedWarning\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nwarnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ── Reproducibility ─────────────────────────────────────────────────────────\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\ntorch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark     = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nN_GPUS = torch.cuda.device_count()\nprint(f\"[HW] device={device}  n_gpus={N_GPUS}\")\nif torch.cuda.is_available():\n    print(f\"[HW] GPU={torch.cuda.get_device_name(0)}  \"\n          f\"VRAM={torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n\n\n# =============================================================================\n# SECTION 1 – CONFIGURATION\n# =============================================================================\n\nclass CFG:\n    # Exact strings required by Kaggle submission\n    CLASSES     = [\"Health\", \"Rust\", \"Other\"]\n    NUM_CLASSES = 3\n    CLASS2IDX   = {\"Health\": 0, \"Rust\": 1, \"Other\": 2}\n    IDX2CLASS   = {0: \"Health\", 1: \"Rust\", 2: \"Other\"}\n\n    # MS: 5 bands [Blue, Green, Red, RedEdge, NIR]\n    # +NDVI +RENDVI injected at runtime → 7 input channels to MS encoder\n    MS_BANDS  = 5\n    MS_IN_CH  = 7\n\n    # HS: 125 total bands (450–950 nm), noisy front-10 & back-14 removed.\n    # EDA peak-variance region: 781–821 nm → absolute band indices 82–92 (11 bands)\n    HS_KEY_BANDS = list(range(82, 93))   # 0-based absolute indices\n    HS_IN_CH     = len(HS_KEY_BANDS)     # = 11\n\n    IMG_SIZE     = 64       # resize target (H, W) for all modalities\n\n    BATCH_SIZE   = 32\n    NUM_WORKERS  = 4\n    LR           = 3e-4\n    WEIGHT_DECAY = 1e-4\n    LABEL_SMOOTH = 0.05\n    VAL_FRAC     = 0.15     # fraction of train used as internal validation\n\n    EPOCHS_S1    = 25       # Stage 1: MS baseline\n    EPOCHS_S2    = 25       # Stage 2: HS core\n    EPOCHS_S3    = 35       # Stage 3: fusion fine-tune\n    WARMUP_EP    = 3        # linear LR warmup epochs\n\n    SUBMISSION   = \"submission.csv\"\n\n\n# =============================================================================\n# SECTION 2 – PATH DETECTION\n# =============================================================================\n\ndef _has_split(p: Path) -> bool:\n    return (p / \"train\").is_dir() and (p / \"val\").is_dir()\n\ndef find_root() -> Path:\n    hardcoded = [\n        \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared\",\n        \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026\",\n        \"/kaggle/input/Kaggle_Prepared\",\n        \"/kaggle/working/Kaggle_Prepared\",\n        \"/kaggle/working\",\n    ]\n    for raw in hardcoded:\n        p = Path(raw)\n        if p.is_dir() and _has_split(p):\n            print(f\"[PATH] Root (hardcoded): {p}\")\n            return p\n\n    kaggle_in = Path(\"/kaggle/input\")\n    if kaggle_in.is_dir():\n        def _walk(base, depth):\n            if depth == 0: return None\n            try:\n                for child in sorted(base.iterdir()):\n                    if not child.is_dir(): continue\n                    if _has_split(child): return child\n                    r = _walk(child, depth - 1)\n                    if r: return r\n            except PermissionError:\n                pass\n            return None\n        found = _walk(kaggle_in, 6)\n        if found:\n            print(f\"[PATH] Root (recursive search): {found}\")\n            return found\n\n    print(\"\\n[FATAL] Could not locate dataset. /kaggle/input tree:\\n\")\n    if kaggle_in.is_dir():\n        for item in sorted(kaggle_in.rglob(\"*\")):\n            d = len(item.relative_to(kaggle_in).parts)\n            if d <= 6:\n                print(\"  \" * d + item.name + (\"/\" if item.is_dir() else \"\"))\n    raise FileNotFoundError(\n        \"Set ROOT manually:\\n\"\n        \"  ROOT=Path('/your/path'); TRAIN_DIR=ROOT/'train'; VAL_DIR=ROOT/'val'\"\n    )\n\nROOT      = find_root()\nTRAIN_DIR = ROOT / \"train\"\nVAL_DIR   = ROOT / \"val\"\nprint(f\"[PATH] TRAIN_DIR = {TRAIN_DIR}\")\nprint(f\"[PATH] VAL_DIR   = {VAL_DIR}\")\n\n\n# =============================================================================\n# SECTION 3 – FILENAME-BASED CLASS EXTRACTION & SAMPLE COLLECTION\n# =============================================================================\n#\n# YOUR DATASET STRUCTURE (confirmed from screenshot):\n#\n#   train/RGB/  ← flat folder, NO class subfolders\n#               Files named:  Health_hyper_1.png\n#                             rust_hyper_2.png\n#                             other_hyper_12.png\n#\n#   train/MS/   ← same stems, .tif extension\n#   train/HS/   ← same stems, .tif extension\n#\n#   val/RGB/    ← flat folder, filenames have NO class prefix\n#               Files named:  val_02afcb0e.png   (class unknown until submission)\n#\n# CLASS EXTRACTION LOGIC:\n#   Split filename stem on \"_\", check if first token matches a known class\n#   (case-insensitive). This correctly handles:\n#     \"Health_hyper_1\"  → \"health\" → Health (label 0)\n#     \"rust_hyper_2\"    → \"rust\"   → Rust   (label 1)\n#     \"other_hyper_12\"  → \"other\"  → Other  (label 2)\n#     \"val_02afcb0e\"    → \"val\"    → None   (label -1, val set only)\n# =============================================================================\n\n# Case-insensitive map: \"health\"/\"HEALTH\"/\"Health\" all → \"Health\"\n_CLS_MAP = {c.lower(): c for c in CFG.CLASSES}\n\ndef class_from_stem(stem: str):\n    \"\"\"\n    Extract class from filename stem using prefix matching.\n    Returns (canonical_class_name, label_int) or (None, -1) if not found.\n\n    Examples:\n      \"Health_hyper_1\"  → (\"Health\", 0)\n      \"rust_hyper_2\"    → (\"Rust\",   1)\n      \"other_hyper_12\"  → (\"Other\",  2)\n      \"val_02afcb0e\"    → (None,    -1)\n    \"\"\"\n    prefix = stem.split(\"_\")[0].lower()\n    canon  = _CLS_MAP.get(prefix)\n    if canon is None:\n        return None, -1\n    return canon, CFG.CLASS2IDX[canon]\n\n\ndef collect_train_samples(split_dir: Path) -> list:\n    \"\"\"\n    Collect training samples from flat RGB folder.\n    Class is extracted from filename prefix.\n    Records with unrecognised prefix are SKIPPED (never label=-1 in train).\n    \"\"\"\n    rgb_dir = split_dir / \"RGB\"\n    ms_dir  = split_dir / \"MS\"\n    hs_dir  = split_dir / \"HS\"\n\n    if not rgb_dir.is_dir():\n        raise RuntimeError(f\"[FATAL] {rgb_dir} not found\")\n\n    all_pngs = sorted(rgb_dir.glob(\"*.png\")) + sorted(rgb_dir.glob(\"*.PNG\"))\n    print(f\"[COLLECT] Train: {len(all_pngs)} PNG files found in {rgb_dir}\")\n\n    records = []\n    skipped = []\n    per_cls = defaultdict(int)\n\n    for png in all_pngs:\n        stem  = png.stem\n        canon, label = class_from_stem(stem)\n\n        if canon is None:\n            skipped.append(stem)\n            continue   # never add with label=-1 to train\n\n        per_cls[canon] += 1\n        records.append({\n            \"stem\":     stem,\n            \"ms_path\":  ms_dir / (stem + \".tif\"),\n            \"hs_path\":  hs_dir / (stem + \".tif\"),\n            \"label\":    label,      # always 0, 1, or 2 here\n            \"cls_name\": canon,\n        })\n\n    print(f\"[COLLECT] Train records: {len(records)}  skipped: {len(skipped)}\")\n    print(f\"[COLLECT] Class distribution: {dict(per_cls)}\")\n    if skipped:\n        print(f\"[COLLECT] Skipped stems (first 5): {skipped[:5]}\")\n\n    return records\n\n\ndef collect_val_samples(split_dir: Path) -> list:\n    \"\"\"\n    Collect validation samples from flat RGB folder.\n    No class labels available → label=-1 (never used in loss function).\n    \"\"\"\n    rgb_dir = split_dir / \"RGB\"\n    ms_dir  = split_dir / \"MS\"\n    hs_dir  = split_dir / \"HS\"\n\n    if not rgb_dir.is_dir():\n        raise RuntimeError(f\"[FATAL] {rgb_dir} not found\")\n\n    all_pngs = sorted(rgb_dir.glob(\"*.png\")) + sorted(rgb_dir.glob(\"*.PNG\"))\n    print(f\"[COLLECT] Val: {len(all_pngs)} PNG files found in {rgb_dir}\")\n\n    records = []\n    for png in all_pngs:\n        stem = png.stem\n        records.append({\n            \"stem\":     stem,\n            \"ms_path\":  ms_dir / (stem + \".tif\"),\n            \"hs_path\":  hs_dir / (stem + \".tif\"),\n            \"label\":    -1,         # unknown – never passed to loss\n            \"cls_name\": \"__val__\",\n        })\n\n    print(f\"[COLLECT] Val records: {len(records)}\")\n    return records\n\n\n# Run collection\ntrain_records = collect_train_samples(TRAIN_DIR)\nval_records   = collect_val_samples(VAL_DIR)\n\n# Hard stop if empty\nif len(train_records) == 0:\n    raise RuntimeError(\n        \"Zero training records collected.\\n\"\n        f\"RGB dir: {TRAIN_DIR/'RGB'}\\n\"\n        \"Check that files are named like 'Health_hyper_1.png', 'rust_hyper_2.png'\"\n    )\nif len(val_records) == 0:\n    raise RuntimeError(f\"Zero val records collected from {VAL_DIR/'RGB'}\")\n\n# Final label integrity check – catches any edge case\nbad = [r for r in train_records if r[\"label\"] not in {0, 1, 2}]\nif bad:\n    raise ValueError(\n        f\"{len(bad)} train records with invalid label. First: {bad[0]}\"\n    )\nprint(f\"\\n[OK] train={len(train_records)}  val={len(val_records)}\")\nprint(\"[OK] All train labels verified in {0,1,2} – no CUDA scatter crash risk\")\n\n\n# =============================================================================\n# SECTION 4 – DATA LOADING UTILITIES\n# =============================================================================\n\ndef load_ms(path: Path) -> torch.Tensor:\n    \"\"\"\n    Load 5-band MS .tif → float32 tensor (5, IMG_SIZE, IMG_SIZE) in [0,1].\n    Per-band 1–99th percentile clipping for robust normalization.\n    \"\"\"\n    with rasterio.open(str(path)) as src:\n        data = src.read().astype(np.float32)          # (bands, H, W)\n    for b in range(data.shape[0]):\n        lo = np.percentile(data[b], 1)\n        hi = np.percentile(data[b], 99)\n        data[b] = np.clip((data[b] - lo) / (hi - lo + 1e-8), 0.0, 1.0)\n    out = np.stack([\n        cv2.resize(data[b], (CFG.IMG_SIZE, CFG.IMG_SIZE),\n                   interpolation=cv2.INTER_LINEAR)\n        for b in range(data.shape[0])\n    ])\n    return torch.from_numpy(out)\n\n\ndef load_hs(path: Path) -> torch.Tensor:\n    \"\"\"\n    Load only the 11 EDA high-variance HS bands (781–821 nm, indices 82–92).\n    Memory saving: 11/125 = 91% vs loading full cube.\n    rasterio uses 1-based band indexing → add 1 to each index.\n    \"\"\"\n    bands_1idx = [b + 1 for b in CFG.HS_KEY_BANDS]\n    with rasterio.open(str(path)) as src:\n        data = src.read(bands_1idx).astype(np.float32)  # (11, H, W)\n    for b in range(data.shape[0]):\n        lo = np.percentile(data[b], 1)\n        hi = np.percentile(data[b], 99)\n        data[b] = np.clip((data[b] - lo) / (hi - lo + 1e-8), 0.0, 1.0)\n    out = np.stack([\n        cv2.resize(data[b], (CFG.IMG_SIZE, CFG.IMG_SIZE),\n                   interpolation=cv2.INTER_LINEAR)\n        for b in range(data.shape[0])\n    ])\n    return torch.from_numpy(out)\n\n\ndef inject_vi(ms: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Append NDVI and RENDVI as channels 5 & 6.\n\n    Input:  (B, 5, H, W)  [Blue, Green, Red, RedEdge, NIR]\n    Output: (B, 7, H, W)\n\n    EDA finding: NDVI is the most discriminative single MS feature.\n    Injecting it directly means early conv filters see it without\n    having to re-derive it from raw band ratios.\n    \"\"\"\n    RED    = ms[:, 2:3]\n    RE     = ms[:, 3:4]\n    NIR    = ms[:, 4:5]\n    NDVI   = (NIR - RED) / (NIR + RED + 1e-8)\n    RENDVI = (NIR - RE)  / (NIR + RE  + 1e-8)\n    # Shift from [-1,1] → [0,1] for consistent CNN input range\n    NDVI   = (NDVI   + 1.0) / 2.0\n    RENDVI = (RENDVI + 1.0) / 2.0\n    return torch.cat([ms, NDVI, RENDVI], dim=1)\n\n\n# =============================================================================\n# SECTION 5 – DATASET CLASS\n# =============================================================================\n\nclass CropDS(Dataset):\n    \"\"\"\n    Loads MS + HS per sample.\n    VI channels (NDVI/RENDVI) are injected in the training loop, not here,\n    so augmentation acts on raw spectral values only.\n    Augmentation: H/V flip + 90° rotation. NO spectral perturbation.\n    \"\"\"\n    def __init__(self, records: list, augment: bool = False):\n        # Safety filter: remove any record with label outside {-1, 0, 1, 2}\n        self.records = [r for r in records\n                        if r[\"label\"] == -1 or r[\"label\"] in CFG.CLASS2IDX.values()]\n        self.augment = augment\n        dropped = len(records) - len(self.records)\n        if dropped:\n            print(f\"[DS] Dropped {dropped} records with invalid labels\")\n\n    def __len__(self): return len(self.records)\n\n    def _aug(self, ms, hs):\n        if random.random() > 0.5:\n            ms = torch.flip(ms, [-1]); hs = torch.flip(hs, [-1])\n        if random.random() > 0.5:\n            ms = torch.flip(ms, [-2]); hs = torch.flip(hs, [-2])\n        k = random.randint(0, 3)\n        if k:\n            ms = torch.rot90(ms, k, [-2, -1])\n            hs = torch.rot90(hs, k, [-2, -1])\n        return ms, hs\n\n    def __getitem__(self, idx):\n        r = self.records[idx]\n        try:\n            ms = load_ms(r[\"ms_path\"])\n        except Exception:\n            ms = torch.zeros(CFG.MS_BANDS, CFG.IMG_SIZE, CFG.IMG_SIZE)\n        try:\n            hs = load_hs(r[\"hs_path\"])\n        except Exception:\n            hs = torch.zeros(CFG.HS_IN_CH, CFG.IMG_SIZE, CFG.IMG_SIZE)\n        if self.augment:\n            ms, hs = self._aug(ms, hs)\n        return {\n            \"ms\":    ms,\n            \"hs\":    hs,\n            \"label\": torch.tensor(r[\"label\"], dtype=torch.long),\n            \"stem\":  r[\"stem\"],\n        }\n\n\n# =============================================================================\n# SECTION 6 – MODEL ARCHITECTURES\n# =============================================================================\n\nclass DSConv(nn.Module):\n    \"\"\"Depthwise-separable conv: ~3× fewer params than standard conv.\"\"\"\n    def __init__(self, ic, oc, stride=1):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(ic, ic, 3, stride=stride, padding=1,\n                      groups=ic, bias=False),          # depthwise\n            nn.Conv2d(ic, oc, 1, bias=False),          # pointwise\n            nn.BatchNorm2d(oc),\n            nn.ReLU6(inplace=True),\n        )\n    def forward(self, x): return self.net(x)\n\n\ndef _backbone(in_ch: int) -> nn.Sequential:\n    \"\"\"Shared CNN backbone: in_ch → 256-dim flattened feature.\"\"\"\n    return nn.Sequential(\n        nn.Conv2d(in_ch, 32, 3, padding=1, bias=False),\n        nn.BatchNorm2d(32), nn.ReLU6(inplace=True),\n        DSConv(32,  64,  stride=2),   # 64→32\n        DSConv(64,  128, stride=2),   # 32→16\n        DSConv(128, 128, stride=2),   # 16→8\n        DSConv(128, 256, stride=2),   # 8→4\n        nn.AdaptiveAvgPool2d(1),      # 4→1 (global average pool)\n        nn.Flatten(),                 # 256\n    )\n\n\nclass MSEncoder(nn.Module):\n    \"\"\"Encoder for 7-ch MS input → 128-dim feature vector.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.bb   = _backbone(CFG.MS_IN_CH)\n        self.head = nn.Sequential(\n            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.3))\n    def forward(self, x): return self.head(self.bb(x))\n\n\nclass HSEncoder(nn.Module):\n    \"\"\"\n    Encoder for 11-ch HS key-band input → 128-dim feature vector.\n    Band-attention gate (1×1 conv + sigmoid) reweights the 11 bands\n    before spatial processing — lets the network learn which bands\n    carry the most disease-specific information (EDA: 781–821 nm region).\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.attn = nn.Sequential(\n            nn.Conv2d(CFG.HS_IN_CH, CFG.HS_IN_CH, 1, bias=False),\n            nn.Sigmoid())\n        self.bb   = _backbone(CFG.HS_IN_CH)\n        self.head = nn.Sequential(\n            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.3))\n    def forward(self, x): return self.head(self.bb(x * self.attn(x)))\n\n\nclass MSModel(nn.Module):\n    \"\"\"Stage 1: MS-only classifier.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.encoder = MSEncoder()\n        self.clf = nn.Linear(128, CFG.NUM_CLASSES)\n    def forward(self, ms, hs=None): return self.clf(self.encoder(ms))\n\n\nclass HSModel(nn.Module):\n    \"\"\"Stage 2: HS-only classifier (11 key bands).\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.encoder = HSEncoder()\n        self.clf = nn.Linear(128, CFG.NUM_CLASSES)\n    def forward(self, ms=None, hs=None): return self.clf(self.encoder(hs))\n\n\nclass FusionModel(nn.Module):\n    \"\"\"\n    Stage 3: Late-fusion MS + HS.\n    Concat(MS-feat[128], HS-feat[128]) → 256 → FC head → 3 classes.\n\n    Why late fusion:\n      MS and HS have different spectral characteristics; mixing them before\n      feature extraction destroys modality-specific structure.\n      Late fusion lets each encoder specialise, then the FC head learns\n      complementary combinations (MS=broad NDVI signal, HS=narrow 781–821nm).\n    \"\"\"\n    def __init__(self, ms_w=None, hs_w=None):\n        super().__init__()\n        self.ms_enc = MSEncoder()\n        self.hs_enc = HSEncoder()\n        if ms_w: self.ms_enc.load_state_dict(ms_w, strict=False)\n        if hs_w: self.hs_enc.load_state_dict(hs_w, strict=False)\n        self.head = nn.Sequential(\n            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.4),\n            nn.Linear(128, 64),  nn.ReLU(inplace=True),\n            nn.Linear(64, CFG.NUM_CLASSES),\n        )\n    def forward(self, ms, hs):\n        return self.head(torch.cat([self.ms_enc(ms), self.hs_enc(hs)], dim=1))\n\n\n# =============================================================================\n# SECTION 7 – TRAINING INFRASTRUCTURE\n# =============================================================================\n\nclass SmoothCE(nn.Module):\n    \"\"\"\n    Label-smoothing cross-entropy.\n    targets.clamp() is a hard safety net against any label=-1 reaching GPU.\n    \"\"\"\n    def __init__(self, nc=CFG.NUM_CLASSES, smooth=CFG.LABEL_SMOOTH):\n        super().__init__()\n        self.nc = nc; self.smooth = smooth\n\n    def forward(self, logits, targets):\n        targets = targets.clamp(0, self.nc - 1)      # safety clamp\n        log_p   = F.log_softmax(logits, dim=-1)\n        with torch.no_grad():\n            t = torch.full_like(log_p, self.smooth / (self.nc - 1))\n            t.scatter_(1, targets.unsqueeze(1), 1.0 - self.smooth)\n        return -(t * log_p).sum(dim=-1).mean()\n\n\ndef _fwd(model, ms, hs, mode):\n    \"\"\"Run forward pass for given mode, injecting VI channels for MS.\"\"\"\n    ms_vi = inject_vi(ms)\n    if   mode == \"ms\":     return model(ms=ms_vi)\n    elif mode == \"hs\":     return model(hs=hs)\n    else:                  return model(ms=ms_vi, hs=hs)\n\n\ndef _filter_batch(ms, hs, label):\n    \"\"\"Drop any sample in a batch whose label is outside {0,1,2}.\"\"\"\n    mask  = (label >= 0) & (label < CFG.NUM_CLASSES)\n    return ms[mask], hs[mask], label[mask]\n\n\ndef train_epoch(model, loader, optimizer, criterion, mode):\n    model.train()\n    loss_sum = correct = total = 0\n    for batch in loader:\n        ms    = batch[\"ms\"].to(device, non_blocking=True)\n        hs    = batch[\"hs\"].to(device, non_blocking=True)\n        label = batch[\"label\"].to(device, non_blocking=True)\n        ms, hs, label = _filter_batch(ms, hs, label)\n        if label.numel() == 0: continue\n\n        optimizer.zero_grad(set_to_none=True)\n        out  = _fwd(model, ms, hs, mode)\n        loss = criterion(out, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        loss_sum += loss.item() * label.size(0)\n        correct  += (out.argmax(1) == label).sum().item()\n        total    += label.size(0)\n    return loss_sum / max(total, 1), correct / max(total, 1)\n\n\n@torch.no_grad()\ndef eval_epoch(model, loader, criterion, mode):\n    model.eval()\n    loss_sum = correct = total = 0\n    for batch in loader:\n        ms    = batch[\"ms\"].to(device, non_blocking=True)\n        hs    = batch[\"hs\"].to(device, non_blocking=True)\n        label = batch[\"label\"].to(device, non_blocking=True)\n        ms, hs, label = _filter_batch(ms, hs, label)\n        if label.numel() == 0: continue\n        out      = _fwd(model, ms, hs, mode)\n        loss     = criterion(out, label)\n        loss_sum += loss.item() * label.size(0)\n        correct  += (out.argmax(1) == label).sum().item()\n        total    += label.size(0)\n    return loss_sum / max(total, 1), correct / max(total, 1)\n\n\ndef train_model(model, tr_ld, va_ld, epochs, lr, mode, ckpt):\n    \"\"\"\n    Training loop:\n      - Linear LR warmup (WARMUP_EP epochs) to stabilise BatchNorm early on\n      - Cosine annealing after warmup (smooth decay suits spectral models)\n      - AdamW optimizer (clean L2 via weight_decay, no grad-norm confusion)\n      - Best checkpoint saved by validation accuracy\n    \"\"\"\n    criterion = SmoothCE().to(device)\n    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=CFG.WEIGHT_DECAY)\n    scheduler = CosineAnnealingLR(optimizer,\n                                  T_max=max(1, epochs - CFG.WARMUP_EP),\n                                  eta_min=lr * 0.01)\n    best_acc = 0.0\n    best_wts = None\n\n    print(f\"\\n{'─'*62}\")\n    print(f\"  mode={mode.upper()}  epochs={epochs}  lr={lr:.0e}\")\n    print(f\"{'─'*62}\")\n\n    for ep in range(1, epochs + 1):\n        if ep <= CFG.WARMUP_EP:\n            for pg in optimizer.param_groups:\n                pg[\"lr\"] = lr * ep / CFG.WARMUP_EP\n\n        tr_l, tr_a = train_epoch(model, tr_ld, optimizer, criterion, mode)\n        va_l, va_a = eval_epoch (model, va_ld, criterion, mode)\n        if ep > CFG.WARMUP_EP: scheduler.step()\n\n        cur_lr = optimizer.param_groups[0][\"lr\"]\n        print(f\"  ep {ep:3d}/{epochs}  \"\n              f\"tr {tr_l:.4f}/{tr_a:.3f}  \"\n              f\"va {va_l:.4f}/{va_a:.3f}  \"\n              f\"lr {cur_lr:.2e}\")\n\n        if va_a > best_acc:\n            best_acc = va_a\n            best_wts = {k: v.clone() for k, v in model.state_dict().items()}\n            torch.save(best_wts, ckpt)\n            print(f\"    ✓ checkpoint saved  val_acc={va_a:.4f}\")\n\n    if best_wts:\n        model.load_state_dict(best_wts)\n    print(f\"  Best val_acc: {best_acc:.4f}\")\n    return model, best_acc\n\n\n# =============================================================================\n# SECTION 8 – DATALOADER SETUP\n# =============================================================================\n\n# Stratified 85/15 internal train/val split\nrandom.shuffle(train_records)\nbuckets = defaultdict(list)\nfor r in train_records:\n    buckets[r[\"label\"]].append(r)\n\nint_train, int_val = [], []\nfor lbl, recs in buckets.items():\n    n_val = max(1, int(len(recs) * CFG.VAL_FRAC))\n    int_val.extend(recs[:n_val])\n    int_train.extend(recs[n_val:])\nrandom.shuffle(int_train); random.shuffle(int_val)\n\nprint(f\"\\n[DS] int_train={len(int_train)}  int_val={len(int_val)}  test={len(val_records)}\")\nfor nm, recs in [(\"int_train\", int_train), (\"int_val\", int_val)]:\n    d = defaultdict(int)\n    for r in recs: d[CFG.IDX2CLASS[r[\"label\"]]] += 1\n    print(f\"[DS] {nm} class dist: {dict(d)}\")\n\n# Final label sanity check before any GPU work\nfor nm, recs in [(\"int_train\", int_train), (\"int_val\", int_val)]:\n    bad = [r for r in recs if r[\"label\"] not in {0, 1, 2}]\n    if bad:\n        raise ValueError(f\"[FATAL] {nm} still has {len(bad)} invalid labels: {bad[0]}\")\nprint(\"[DS] Label sanity check PASSED – safe to train\")\n\ntrain_ds = CropDS(int_train,   augment=True)\nval_ds   = CropDS(int_val,     augment=False)\ntest_ds  = CropDS(val_records, augment=False)\n\nkw = dict(num_workers=CFG.NUM_WORKERS, pin_memory=True)\ntrain_ld = DataLoader(train_ds, CFG.BATCH_SIZE, shuffle=True,  drop_last=True,  **kw)\nval_ld   = DataLoader(val_ds,   CFG.BATCH_SIZE, shuffle=False, drop_last=False, **kw)\ntest_ld  = DataLoader(test_ds,  CFG.BATCH_SIZE, shuffle=False, drop_last=False, **kw)\nprint(f\"[DS] batches – train={len(train_ld)}  val={len(val_ld)}  test={len(test_ld)}\")\n\n\n# =============================================================================\n# SECTION 9 – STAGE 1: MS BASELINE\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*62)\nprint(\"  STAGE 1 – Multispectral Baseline (5 bands + NDVI + RENDVI)\")\nprint(\"=\"*62)\n\nmodel_ms = MSModel().to(device)\nif N_GPUS > 1:\n    model_ms = nn.DataParallel(model_ms)\n    print(f\"[HW] DataParallel × {N_GPUS} GPUs\")\n\nmodel_ms, acc_s1 = train_model(model_ms, train_ld, val_ld,\n                                CFG.EPOCHS_S1, CFG.LR, \"ms\", \"ckpt_ms.pth\")\nprint(f\"\\n[S1 DONE] best val_acc = {acc_s1:.4f}\")\n\n\n# =============================================================================\n# SECTION 10 – STAGE 2: HS CORE MODEL\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*62)\nprint(\"  STAGE 2 – Hyperspectral Core (11 bands, 781–821 nm)\")\nprint(\"=\"*62)\n\nmodel_hs = HSModel().to(device)\nif N_GPUS > 1:\n    model_hs = nn.DataParallel(model_hs)\n\nmodel_hs, acc_s2 = train_model(model_hs, train_ld, val_ld,\n                                CFG.EPOCHS_S2, CFG.LR, \"hs\", \"ckpt_hs.pth\")\nprint(f\"\\n[S2 DONE] best val_acc = {acc_s2:.4f}\")\n\n\n# =============================================================================\n# SECTION 11 – STAGE 3: FUSION\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*62)\nprint(\"  STAGE 3 – MS + HS Late-Fusion Model\")\nprint(\"=\"*62)\n\ndef _enc_w(m):\n    \"\"\"Unwrap DataParallel and return encoder state dict.\"\"\"\n    core = m.module if isinstance(m, nn.DataParallel) else m\n    return core.encoder.state_dict() if hasattr(core, \"encoder\") else None\n\nmodel_fusion = FusionModel(ms_w=_enc_w(model_ms),\n                           hs_w=_enc_w(model_hs)).to(device)\nif N_GPUS > 1:\n    model_fusion = nn.DataParallel(model_fusion)\n\n# Phase A: freeze encoders → train only fusion head (fast warm-start)\nprint(\"\\n[Phase A] Fusion head only – encoders frozen (5 epochs)\")\nfcore = model_fusion.module if isinstance(model_fusion, nn.DataParallel) else model_fusion\nfor p in list(fcore.ms_enc.parameters()) + list(fcore.hs_enc.parameters()):\n    p.requires_grad = False\n\nmodel_fusion, _ = train_model(model_fusion, train_ld, val_ld,\n                               5, CFG.LR * 2, \"fusion\", \"ckpt_fA.pth\")\n\n# Phase B: unfreeze everything → full end-to-end fine-tune at lower LR\nprint(\"\\n[Phase B] End-to-end fine-tune – all layers unfrozen\")\nfor p in list(fcore.ms_enc.parameters()) + list(fcore.hs_enc.parameters()):\n    p.requires_grad = True\n\nmodel_fusion, acc_s3 = train_model(model_fusion, train_ld, val_ld,\n                                    CFG.EPOCHS_S3, CFG.LR / 3,\n                                    \"fusion\", \"ckpt_fusion.pth\")\nprint(f\"\\n[S3 DONE] best val_acc = {acc_s3:.4f}\")\n\n\n# =============================================================================\n# SECTION 12 – ABLATION SUMMARY\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*62)\nprint(\"  ABLATION SUMMARY (internal val)\")\nprint(\"=\"*62)\nprint(f\"  Stage 1  MS  baseline  : {acc_s1:.4f}\")\nprint(f\"  Stage 2  HS  core      : {acc_s2:.4f}\")\nprint(f\"  Stage 3  Fusion        : {acc_s3:.4f}\")\nprint(\"  Expected: Fusion ≥ HS > MS  (confirmed by EDA)\")\nprint(\"=\"*62)\n\n\n# =============================================================================\n# SECTION 13 – INFERENCE & SUBMISSION\n# =============================================================================\n\n@torch.no_grad()\ndef run_inference(model, loader, mode, tta=True):\n    \"\"\"\n    Inference with horizontal-flip TTA (spatial only, no spectral jitter).\n    Returns list of {\"Id\": stem, \"Category\": class_name}.\n    \"\"\"\n    model.eval()\n    rows = []\n    for batch in loader:\n        ms    = batch[\"ms\"].to(device, non_blocking=True)\n        hs    = batch[\"hs\"].to(device, non_blocking=True)\n        stems = batch[\"stem\"]\n\n        probs = F.softmax(_fwd(model, ms, hs, mode), dim=-1)\n        if tta:\n            ms_f  = torch.flip(ms, [-1])\n            hs_f  = torch.flip(hs, [-1])\n            probs = (probs + F.softmax(_fwd(model, ms_f, hs_f, mode), dim=-1)) / 2.0\n\n        preds = probs.argmax(dim=1).cpu().numpy()\n        for stem, pred in zip(stems, preds):\n            rows.append({\"Id\": stem, \"Category\": CFG.IDX2CLASS[int(pred)]})\n    return rows\n\n\nprint(\"\\n[INFERENCE] Running on val set with fusion model + TTA…\")\nrows = run_inference(model_fusion, test_ld, \"fusion\", tta=True)\nsub  = pd.DataFrame(rows)\n\nprint(f\"[INFERENCE] Rows      : {len(sub)}\")\nprint(f\"[INFERENCE] Class dist:\\n{sub['Category'].value_counts()}\")\n\n# Verify no invalid class names leaked into output\ninvalid = set(sub[\"Category\"].unique()) - set(CFG.CLASSES)\nassert not invalid, f\"Invalid class names in submission: {invalid}\"\n\nsub.to_csv(CFG.SUBMISSION, index=False)\nprint(f\"[INFERENCE] Saved → {CFG.SUBMISSION}\")\nprint(sub.head(8).to_string(index=False))\n\n\n# =============================================================================\n# SECTION 14 – SELF-EVALUATION (if result.csv present in val/)\n# =============================================================================\n\nresult_csv = VAL_DIR / \"result.csv\"\nif result_csv.exists():\n    print(\"\\n\" + \"=\"*62)\n    print(\"  SELF-EVALUATION  (result.csv found)\")\n    print(\"=\"*62)\n    gt    = pd.read_csv(result_csv)\n    id_c  = next((c for c in gt.columns if c.lower() in {\"id\",\"filename\",\"stem\"}), None)\n    cat_c = next((c for c in gt.columns if c.lower() in {\"category\",\"label\",\"class\"}), None)\n    if id_c and cat_c:\n        gt  = gt.rename(columns={id_c: \"Id\", cat_c: \"gt\"})\n        mg  = sub.merge(gt[[\"Id\",\"gt\"]], on=\"Id\")\n        acc = (mg[\"Category\"] == mg[\"gt\"]).mean()\n        print(f\"  Overall accuracy : {acc:.4f}  (n={len(mg)})\")\n        for cls in CFG.CLASSES:\n            m = mg[\"gt\"] == cls\n            c = (mg.loc[m, \"Category\"] == cls).sum()\n            print(f\"    {cls:8s}: {c}/{m.sum()} = {c/max(m.sum(),1):.4f}\")\n    else:\n        print(f\"  Unexpected GT columns: {list(gt.columns)}\")\nelse:\n    print(\"\\n[INFO] No result.csv in val/ – Kaggle-style hidden labels.\")\n    print(f\"[INFO] Upload {CFG.SUBMISSION} to the competition leaderboard.\")\n\n\nprint(\"\\n\" + \"=\"*62)\nprint(\"  PIPELINE COMPLETE\")\nprint(f\"  MS  baseline  val_acc : {acc_s1:.4f}\")\nprint(f\"  HS  core      val_acc : {acc_s2:.4f}\")\nprint(f\"  Fusion        val_acc : {acc_s3:.4f}\")\nprint(f\"  Output                : {CFG.SUBMISSION}\")\nprint(\"=\"*62)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:31:45.296373Z","iopub.execute_input":"2026-02-20T04:31:45.297416Z","iopub.status.idle":"2026-02-20T04:45:15.889961Z","shell.execute_reply.started":"2026-02-20T04:31:45.297354Z","shell.execute_reply":"2026-02-20T04:45:15.888701Z"}},"outputs":[{"name":"stdout","text":"[HW] device=cpu  n_gpus=0\n[PATH] Root (hardcoded): /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared\n[PATH] TRAIN_DIR = /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared/train\n[PATH] VAL_DIR   = /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared/val\n[COLLECT] Train: 600 PNG files found in /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared/train/RGB\n[COLLECT] Train records: 600  skipped: 0\n[COLLECT] Class distribution: {'Health': 200, 'Other': 200, 'Rust': 200}\n[COLLECT] Val: 300 PNG files found in /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared/val/RGB\n[COLLECT] Val records: 300\n\n[OK] train=600  val=300\n[OK] All train labels verified in {0,1,2} – no CUDA scatter crash risk\n\n[DS] int_train=510  int_val=90  test=300\n[DS] int_train class dist: {'Rust': 170, 'Other': 170, 'Health': 170}\n[DS] int_val class dist: {'Other': 30, 'Health': 30, 'Rust': 30}\n[DS] Label sanity check PASSED – safe to train\n[DS] batches – train=15  val=3  test=10\n\n==============================================================\n  STAGE 1 – Multispectral Baseline (5 bands + NDVI + RENDVI)\n==============================================================\n\n──────────────────────────────────────────────────────────────\n  mode=MS  epochs=25  lr=3e-04\n──────────────────────────────────────────────────────────────\n  ep   1/25  tr 1.1039/0.321  va 1.0987/0.333  lr 1.00e-04\n    ✓ checkpoint saved  val_acc=0.3333\n  ep   2/25  tr 1.0890/0.394  va 1.0962/0.333  lr 2.00e-04\n  ep   3/25  tr 1.0648/0.460  va 1.0677/0.467  lr 3.00e-04\n    ✓ checkpoint saved  val_acc=0.4667\n  ep   4/25  tr 1.0371/0.498  va 1.0343/0.467  lr 2.98e-04\n  ep   5/25  tr 1.0122/0.523  va 1.0097/0.489  lr 2.94e-04\n    ✓ checkpoint saved  val_acc=0.4889\n  ep   6/25  tr 0.9931/0.533  va 0.9751/0.533  lr 2.87e-04\n    ✓ checkpoint saved  val_acc=0.5333\n  ep   7/25  tr 0.9896/0.533  va 0.9966/0.533  lr 2.76e-04\n  ep   8/25  tr 0.9527/0.573  va 0.9591/0.544  lr 2.64e-04\n    ✓ checkpoint saved  val_acc=0.5444\n  ep   9/25  tr 0.9592/0.556  va 0.9452/0.533  lr 2.49e-04\n  ep  10/25  tr 0.9457/0.573  va 0.9505/0.567  lr 2.32e-04\n    ✓ checkpoint saved  val_acc=0.5667\n  ep  11/25  tr 0.9349/0.581  va 0.9480/0.489  lr 2.13e-04\n  ep  12/25  tr 0.9326/0.562  va 0.9353/0.544  lr 1.93e-04\n  ep  13/25  tr 0.9208/0.581  va 0.9437/0.556  lr 1.73e-04\n  ep  14/25  tr 0.9064/0.606  va 0.9467/0.533  lr 1.51e-04\n  ep  15/25  tr 0.8941/0.602  va 0.9339/0.567  lr 1.30e-04\n  ep  16/25  tr 0.9000/0.588  va 0.9383/0.544  lr 1.10e-04\n  ep  17/25  tr 0.8878/0.619  va 0.9399/0.567  lr 8.98e-05\n  ep  18/25  tr 0.8878/0.606  va 0.9419/0.544  lr 7.12e-05\n  ep  19/25  tr 0.8805/0.637  va 0.9469/0.533  lr 5.43e-05\n  ep  20/25  tr 0.8757/0.627  va 0.9416/0.544  lr 3.93e-05\n  ep  21/25  tr 0.8854/0.606  va 0.9378/0.533  lr 2.66e-05\n  ep  22/25  tr 0.8600/0.627  va 0.9340/0.533  lr 1.64e-05\n  ep  23/25  tr 0.8745/0.631  va 0.9372/0.544  lr 9.02e-06\n  ep  24/25  tr 0.8925/0.590  va 0.9346/0.544  lr 4.51e-06\n  ep  25/25  tr 0.8690/0.633  va 0.9357/0.544  lr 3.00e-06\n  Best val_acc: 0.5667\n\n[S1 DONE] best val_acc = 0.5667\n\n==============================================================\n  STAGE 2 – Hyperspectral Core (11 bands, 781–821 nm)\n==============================================================\n\n──────────────────────────────────────────────────────────────\n  mode=HS  epochs=25  lr=3e-04\n──────────────────────────────────────────────────────────────\n  ep   1/25  tr 1.0984/0.344  va 1.0989/0.333  lr 1.00e-04\n    ✓ checkpoint saved  val_acc=0.3333\n  ep   2/25  tr 1.0903/0.356  va 1.0983/0.311  lr 2.00e-04\n  ep   3/25  tr 1.0756/0.392  va 1.0956/0.289  lr 3.00e-04\n  ep   4/25  tr 1.0557/0.419  va 1.1543/0.311  lr 2.98e-04\n  ep   5/25  tr 1.0281/0.477  va 1.0267/0.500  lr 2.94e-04\n    ✓ checkpoint saved  val_acc=0.5000\n  ep   6/25  tr 1.0130/0.492  va 1.0423/0.389  lr 2.87e-04\n  ep   7/25  tr 1.0031/0.498  va 1.1202/0.356  lr 2.76e-04\n  ep   8/25  tr 0.9988/0.521  va 2.3314/0.311  lr 2.64e-04\n  ep   9/25  tr 0.9883/0.517  va 0.9718/0.478  lr 2.49e-04\n  ep  10/25  tr 0.9778/0.542  va 1.3008/0.367  lr 2.32e-04\n  ep  11/25  tr 0.9838/0.519  va 1.4416/0.356  lr 2.13e-04\n  ep  12/25  tr 1.0062/0.483  va 1.6468/0.356  lr 1.93e-04\n  ep  13/25  tr 0.9762/0.544  va 1.1004/0.400  lr 1.73e-04\n  ep  14/25  tr 0.9640/0.535  va 0.9503/0.533  lr 1.51e-04\n    ✓ checkpoint saved  val_acc=0.5333\n  ep  15/25  tr 0.9657/0.535  va 0.9460/0.489  lr 1.30e-04\n  ep  16/25  tr 0.9905/0.504  va 0.9367/0.511  lr 1.10e-04\n  ep  17/25  tr 0.9710/0.515  va 0.9537/0.533  lr 8.98e-05\n  ep  18/25  tr 0.9527/0.533  va 1.0087/0.433  lr 7.12e-05\n  ep  19/25  tr 0.9687/0.531  va 0.9429/0.489  lr 5.43e-05\n  ep  20/25  tr 0.9687/0.492  va 0.9424/0.522  lr 3.93e-05\n  ep  21/25  tr 0.9707/0.533  va 0.9371/0.556  lr 2.66e-05\n    ✓ checkpoint saved  val_acc=0.5556\n  ep  22/25  tr 0.9496/0.546  va 0.9340/0.578  lr 1.64e-05\n    ✓ checkpoint saved  val_acc=0.5778\n  ep  23/25  tr 0.9501/0.540  va 0.9317/0.578  lr 9.02e-06\n  ep  24/25  tr 0.9643/0.529  va 0.9327/0.544  lr 4.51e-06\n  ep  25/25  tr 0.9441/0.569  va 0.9281/0.578  lr 3.00e-06\n  Best val_acc: 0.5778\n\n[S2 DONE] best val_acc = 0.5778\n\n==============================================================\n  STAGE 3 – MS + HS Late-Fusion Model\n==============================================================\n\n[Phase A] Fusion head only – encoders frozen (5 epochs)\n\n──────────────────────────────────────────────────────────────\n  mode=FUSION  epochs=5  lr=6e-04\n──────────────────────────────────────────────────────────────\n  ep   1/5  tr 1.0932/0.377  va 1.0714/0.422  lr 2.00e-04\n    ✓ checkpoint saved  val_acc=0.4222\n  ep   2/5  tr 1.0590/0.483  va 1.0169/0.578  lr 4.00e-04\n    ✓ checkpoint saved  val_acc=0.5778\n  ep   3/5  tr 0.9965/0.560  va 0.9421/0.578  lr 6.00e-04\n  ep   4/5  tr 0.9326/0.583  va 0.9128/0.578  lr 3.03e-04\n  ep   5/5  tr 0.9032/0.590  va 0.9126/0.611  lr 6.00e-06\n    ✓ checkpoint saved  val_acc=0.6111\n  Best val_acc: 0.6111\n\n[Phase B] End-to-end fine-tune – all layers unfrozen\n\n──────────────────────────────────────────────────────────────\n  mode=FUSION  epochs=35  lr=1e-04\n──────────────────────────────────────────────────────────────\n  ep   1/35  tr 0.9075/0.613  va 0.9026/0.611  lr 3.33e-05\n    ✓ checkpoint saved  val_acc=0.6111\n  ep   2/35  tr 0.9212/0.602  va 0.9010/0.611  lr 6.67e-05\n  ep   3/35  tr 0.9104/0.583  va 0.8950/0.622  lr 1.00e-04\n    ✓ checkpoint saved  val_acc=0.6222\n  ep   4/35  tr 0.9080/0.610  va 0.9352/0.556  lr 9.98e-05\n  ep   5/35  tr 0.9094/0.560  va 0.8863/0.589  lr 9.90e-05\n  ep   6/35  tr 0.8959/0.598  va 0.8774/0.600  lr 9.79e-05\n  ep   7/35  tr 0.8846/0.594  va 0.9073/0.556  lr 9.62e-05\n  ep   8/35  tr 0.8747/0.602  va 0.8985/0.578  lr 9.42e-05\n  ep   9/35  tr 0.8836/0.606  va 0.8903/0.633  lr 9.17e-05\n    ✓ checkpoint saved  val_acc=0.6333\n  ep  10/35  tr 0.8947/0.598  va 0.8702/0.600  lr 8.88e-05\n  ep  11/35  tr 0.8714/0.617  va 0.8820/0.622  lr 8.55e-05\n  ep  12/35  tr 0.8688/0.615  va 0.8836/0.578  lr 8.19e-05\n  ep  13/35  tr 0.8524/0.642  va 0.9045/0.533  lr 7.80e-05\n  ep  14/35  tr 0.8601/0.642  va 0.8980/0.567  lr 7.38e-05\n  ep  15/35  tr 0.8690/0.615  va 0.8932/0.611  lr 6.94e-05\n  ep  16/35  tr 0.8702/0.600  va 0.8883/0.578  lr 6.49e-05\n  ep  17/35  tr 0.8730/0.613  va 0.8750/0.633  lr 6.02e-05\n  ep  18/35  tr 0.8461/0.648  va 0.8865/0.611  lr 5.54e-05\n  ep  19/35  tr 0.8545/0.617  va 0.8767/0.600  lr 5.05e-05\n  ep  20/35  tr 0.8518/0.640  va 0.8791/0.622  lr 4.56e-05\n  ep  21/35  tr 0.8465/0.648  va 0.8810/0.589  lr 4.08e-05\n  ep  22/35  tr 0.8416/0.642  va 0.9083/0.578  lr 3.61e-05\n  ep  23/35  tr 0.8345/0.646  va 0.8893/0.556  lr 3.16e-05\n  ep  24/35  tr 0.8491/0.629  va 0.8814/0.589  lr 2.72e-05\n  ep  25/35  tr 0.8273/0.660  va 0.8857/0.600  lr 2.30e-05\n  ep  26/35  tr 0.8226/0.654  va 0.8870/0.600  lr 1.91e-05\n  ep  27/35  tr 0.8595/0.635  va 0.8860/0.611  lr 1.55e-05\n  ep  28/35  tr 0.8457/0.635  va 0.8815/0.633  lr 1.22e-05\n  ep  29/35  tr 0.8539/0.640  va 0.8823/0.622  lr 9.34e-06\n  ep  30/35  tr 0.8269/0.673  va 0.8801/0.622  lr 6.84e-06\n  ep  31/35  tr 0.8420/0.646  va 0.8806/0.611  lr 4.77e-06\n  ep  32/35  tr 0.8417/0.627  va 0.8800/0.600  lr 3.13e-06\n  ep  33/35  tr 0.8473/0.658  va 0.8807/0.611  lr 1.95e-06\n  ep  34/35  tr 0.8402/0.623  va 0.8792/0.633  lr 1.24e-06\n  ep  35/35  tr 0.8542/0.631  va 0.8789/0.611  lr 1.00e-06\n  Best val_acc: 0.6333\n\n[S3 DONE] best val_acc = 0.6333\n\n==============================================================\n  ABLATION SUMMARY (internal val)\n==============================================================\n  Stage 1  MS  baseline  : 0.5667\n  Stage 2  HS  core      : 0.5778\n  Stage 3  Fusion        : 0.6333\n  Expected: Fusion ≥ HS > MS  (confirmed by EDA)\n==============================================================\n\n[INFERENCE] Running on val set with fusion model + TTA…\n[INFERENCE] Rows      : 300\n[INFERENCE] Class dist:\nCategory\nRust      170\nOther      78\nHealth     52\nName: count, dtype: int64\n[INFERENCE] Saved → submission.csv\n          Id Category\nval_000a83c1    Other\nval_00a704b1     Rust\nval_01dde030    Other\nval_024df365     Rust\nval_02afcb0e     Rust\nval_03864ba6     Rust\nval_0537e324     Rust\nval_059983e0     Rust\n\n[INFO] No result.csv in val/ – Kaggle-style hidden labels.\n[INFO] Upload submission.csv to the competition leaderboard.\n\n==============================================================\n  PIPELINE COMPLETE\n  MS  baseline  val_acc : 0.5667\n  HS  core      val_acc : 0.5778\n  Fusion        val_acc : 0.6333\n  Output                : submission.csv\n==============================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}